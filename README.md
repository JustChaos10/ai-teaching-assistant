# AI Teaching Assistant

An **AI-powered teaching assistant** with interactive games, chatbot prompts, image detection modules, and teacher-student interfaces â€” all built in Python. The goal is to make learning engaging through gamification and AI-driven interactions.

---

## âœ¨ Features

- ğŸ® **Gamified Learning**
  - Finger counting games
  - Fruits vs. vegetables classification
  - Healthy vs. junk food activities
  - Puzzle and sprite-based exercises

- ğŸ¤– **Chatbot & Prompts**
  - Chatbot logic with custom teaching prompts
  - Avatar system for more engaging conversations

- ğŸ‘©â€ğŸ« **Teacher Interface**
  - Launch and control teacher-facing UI
  - Manage prompts, sessions, and activities

- ğŸ–¼ **Image Detection**
  - Simple computer vision modules for interactive lessons
  - Image datasets and detectors for practice tasks

- ğŸ›  **Modular Architecture**
  - Backend with multiple Python modules
  - Extendable design for adding new games or teaching modules

---

## ğŸ“‚ Project Structure

```bash
ai-teaching-assistant/
â”œâ”€â”€ .env.example                        # Example environment variable file
â”œâ”€â”€ .gitignore                          # Ignored files and directories
â”œâ”€â”€ .gitattributes                      # Git LFS and line-ending settings
â”œâ”€â”€ README.md                           # Main project documentation
â”œâ”€â”€ LICENSE                             # License file
â”‚
â”œâ”€â”€ backend/                            # ğŸ§© Core backend system (FastAPI + RAG)
â”‚   â”œâ”€â”€ app.py                          # FastAPI server with /ask and /audio endpoints
â”‚   â”œâ”€â”€ teacher_chatbot.py              # Main TeacherChatbot class (STT â†’ LLM â†’ TTS â†’ Rhubarb)
â”‚   â”œâ”€â”€ teacher_chatbot_app.py          # Backend entrypoint (integrates chatbot pipeline)
â”‚   â”œâ”€â”€ rag_system.py                   # Retrieval-Augmented Generation system (RAG)
â”‚   â”œâ”€â”€ requirements.txt                # Backend dependencies
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ test.html                   # Simple frontend for testing API uploads
â”‚   â”œâ”€â”€ docs/                           # Educational content (ingested into RAG)
â”‚   â”‚   â”œâ”€â”€ aejm101.pdf â€¦ aemr1ps.pdf   # Teaching material PDFs
â”‚   â”œâ”€â”€ indexes/faiss_index/            # Vector database (FAISS index)
â”‚   â”‚   â”œâ”€â”€ index.faiss
â”‚   â”‚   â””â”€â”€ index.pkl
â”‚   â””â”€â”€ outputs/                        # Generated TTS audio + Rhubarb phoneme JSONs
â”‚
â”œâ”€â”€ humanoid/                           # ğŸ§ Frontend humanoid avatar system (React Three Fiber)
â”‚   â””â”€â”€ r3f-lipsync-tutorial/           # React + Three.js + ReadyPlayerMe + Rhubarb
â”‚       â”œâ”€â”€ public/
â”‚       â”‚   â”œâ”€â”€ animations/             # FBX animation clips (Idle, Greeting, Speaking, etc.)
â”‚       â”‚   â”œâ”€â”€ audios/                 # Example test audios
â”‚       â”‚   â”œâ”€â”€ models/                 # Avatar GLB model
â”‚       â”‚   â””â”€â”€ textures/               # Background images
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ components/
â”‚       â”‚   â”‚   â”œâ”€â”€ Avatar.jsx          # Avatar component â€” handles lip sync & expressions
â”‚       â”‚   â”‚   â””â”€â”€ Experience.jsx      # Scene setup (camera, lighting, animations)
â”‚       â”‚   â”œâ”€â”€ App.jsx                 # Main React app component
â”‚       â”‚   â””â”€â”€ main.jsx                # Entry point for Vite app
â”‚       â”œâ”€â”€ vite.config.js              # Vite configuration
â”‚       â””â”€â”€ package.json                # Frontend dependencies
â”‚
â”œâ”€â”€ image detector/                     # ğŸ–¼ï¸ Interactive learning mini-games (CV-based)
â”‚   â”œâ”€â”€ detector.py                     # Core object detection logic
â”‚   â”œâ”€â”€ finger_counting_game.py         # Hand gesture recognition (counting fingers)
â”‚   â”œâ”€â”€ fruits_vs_vegetables.py         # Food classification game
â”‚   â”œâ”€â”€ healthyVSjunk.py                # Healthy vs junk food detection
â”‚   â”œâ”€â”€ puzzle.py                       # Simple image puzzle game
â”‚   â”œâ”€â”€ images/, temp_images/           # Game assets and temp storage
â”‚   â”œâ”€â”€ puzzle_sprites/                 # Sprite assets for puzzles
â”‚   â””â”€â”€ requirements.txt                # Requirements for image detector subsystem
â”‚
â”œâ”€â”€ animations/                         # ğŸŒ€ GIF animations for idle/listening/speaking states
â”‚   â”œâ”€â”€ idle.gif
â”‚   â”œâ”€â”€ listening.gif
â”‚   â”œâ”€â”€ speaking.gif
â”‚   â”œâ”€â”€ thinking.gif
â”‚   â””â”€â”€ index.html                      # Test page for displaying animations
â”‚
â”œâ”€â”€ asset/                              # âš™ï¸ (LFS) Model weights (not pushed to GitHub)
â”‚   â”œâ”€â”€ DVAE.safetensors
â”‚   â”œâ”€â”€ Decoder.safetensors
â”‚   â”œâ”€â”€ Embed.safetensors
â”‚   â”œâ”€â”€ Vocos.safetensors
â”‚   â””â”€â”€ gpt/model.safetensors
â”‚
â”œâ”€â”€ requirements.txt                    # Master dependency list (for deployment)
â”œâ”€â”€ requirements_updated.txt            # Expanded dependencies (merged envs)
â”‚
â”œâ”€â”€ launch_teacher_interface.py         # Main launcher for full AI assistant
â”œâ”€â”€ teacher_interface.py                # GUI interface for chatbot
â”œâ”€â”€ module_executor.py                  # Runtime module manager (voice, CV, chatbot)
â”œâ”€â”€ chatbot_logic.py                    # Chat reasoning and dialogue logic
â”œâ”€â”€ setup_api_keys.py                   # Utility for setting environment variables
â”œâ”€â”€ quick_test.py                       # Script for testing API flow (STT â†’ LLM â†’ TTS)
â”‚
â”œâ”€â”€ FIXED_SPEECH_ISSUES.md              # Documentation of fixed issues in TTS/STT
â”œâ”€â”€ ISSUES_FIXED_SUMMARY.md             # Summary of fixes and known issues
â”œâ”€â”€ README_TEACHER_SYSTEM.md            # Backend system documentation
â”œâ”€â”€ SPEECH_RECOGNITION_GUIDE.md         # Guide for speech pipeline setup
â”œâ”€â”€ TEST_RESULTS.md                     # Logs and evaluation results
â””â”€â”€ runnotes.txt                        # Developer notes and run instructions

```

---

## ğŸš€ Getting Started

### 1. Clone the repository
```bash
git clone https://github.com/<your-username>/ai-teaching-assistant.git
cd ai-teaching-assistant
```

### 2. Create a virtual environment
```bash
python -m venv venv
source venv/bin/activate   # On Linux/Mac
venv\Scripts\activate    # On Windows
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Run the teacher interface
```bash
python launch_teacher_interface.py
```

---

## âš™ï¸ Requirements

- Python 3.9+
- Libraries listed in `requirements.txt` (e.g., OpenAI, Gradio, Torch, etc. depending on your modules)
- (Optional) Webcam for image-based activities

---

## ğŸ” Environment Variables

Create a `.env` file in the project root with the following (example):

```bash
OPENAI_API_KEY=your_api_key_here
```

---

## ğŸ›¡ï¸ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

---

## ğŸ™Œ Contributions

Contributions, issues, and feature requests are welcome!  
Feel free to fork this repo and open a pull request.

---

## ğŸ“Œ Notes

- This project is modular â€” add new games by creating a Python module and linking it in `game_manager.py`.

---

## ğŸ¯ Roadmap

- Add more AI-driven activities
- Improve computer vision modules
- Expand teacher dashboard with analytics
- Support for multilingual prompts
